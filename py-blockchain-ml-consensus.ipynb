{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_seed = 42 #set random state to this variable (when applicable) so results can be reproduced\n",
    "\n",
    "clfList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating partial slices of the existing train set \n",
    "X_train2 = X_train[:249]\n",
    "y_train2 = y_train[:249]\n",
    "\n",
    "X_train3 = X_train[250:]\n",
    "y_train3 = y_train[250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner:\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.performance = 0\n",
    "        self.correctPredictions = 0\n",
    "        self.predictionsMade = 0\n",
    "        self.currentPred = -1\n",
    "    def getPerformance(self):\n",
    "        return float(self.correctPredictions / self.predictionsMade)\n",
    "    def getClf(self):\n",
    "        return self.clf\n",
    "    def setCurrentPred(self, pred):\n",
    "        self.currentPred = pred\n",
    "    def predict(self, data):\n",
    "        self.setCurrentPred(self.clf.predict(data))\n",
    "        return self.currentPred\n",
    "    def predict_proba(self, data):\n",
    "        temp = self.clf.predict_proba(data)\n",
    "        if temp[0][0] > temp[0][1]:\n",
    "            self.setCurrentPred(0)\n",
    "        else:\n",
    "            self.setCurrentPred(1)\n",
    "        return temp\n",
    "    def updatePrediction(self, val):\n",
    "        self.predictionsMade = self.predictionsMade + 1\n",
    "        if self.currentPred == val:\n",
    "            self.correctPredictions = self.correctPredictions + 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=random_seed)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=random_seed)\n",
    "dt = dt.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=random_seed)\n",
    "dt = dt.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=random_seed)\n",
    "lr = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=random_seed)\n",
    "lr = lr.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=random_seed)\n",
    "lr = lr.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=random_seed)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=random_seed)\n",
    "rf = rf.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=random_seed)\n",
    "rf = rf.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb = nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb = nb.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb = nb.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', probability=True, random_state=random_seed)\n",
    "svc = svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear', probability=True, random_state=random_seed)\n",
    "svc = svc.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear', probability=True, random_state=random_seed)\n",
    "svc = svc.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train3, y_train3)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "clfList.append(Miner(knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq, random\n",
    "\n",
    "class Chain:\n",
    "    def __init__(self):\n",
    "        self.blockList = []\n",
    "    def addToChain(self, block):\n",
    "        self.blockList.append(block)\n",
    "    def getBlockList(self):\n",
    "        return self.blockList\n",
    "    \n",
    "class Block:\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "def pickRandomValidator(minerList):\n",
    "    validator = random.choice(minerList)\n",
    "    minerList.remove(validator)\n",
    "    return validator\n",
    "\n",
    "def pickBestValidator(minerList):\n",
    "    accList = []\n",
    "    for clf in minerList:\n",
    "        accList.append(clf.getPerformance())\n",
    "    validator = minerList[accList.index(max(accList))]\n",
    "    minerList.remove(validator)\n",
    "    return validator\n",
    "\n",
    "def pickFromTopValidator(minerList):\n",
    "    topList = []\n",
    "    for clf in minerList:\n",
    "        if len(topList) < 5:\n",
    "            topList.append(clf)\n",
    "        else:\n",
    "            for cand in topList:\n",
    "                if clf.getPerformance() > cand.getPerformance():\n",
    "                    topList.append(clf)\n",
    "                    topList.remove(cand)\n",
    "    validator = random.choice(topList)\n",
    "    minerList.remove(validator)\n",
    "    return validator\n",
    "\n",
    "\n",
    "def validateData(minerList, validator, data):\n",
    "    mProba = [0, 0]\n",
    "    for clf in minerList:\n",
    "        mProba = mProba + clf.predict_proba(data)\n",
    "    mProba = mProba / len(minerList)\n",
    "\n",
    "    if mProba[0][0] > mProba[0][1]:\n",
    "        consensus = 0\n",
    "    else:\n",
    "        consensus = 1\n",
    "        \n",
    "    vPred = validator.predict(data)\n",
    "    for clf in minerList:\n",
    "        clf.updatePrediction(vPred)\n",
    "    if consensus == vPred:\n",
    "        return consensus\n",
    "    else:\n",
    "        validator = None\n",
    "        return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM VALIDATOR PER ROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Chain() #Instantiate a test blockchain\n",
    "\n",
    "failcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Failed 474 times.\n",
      "Final block height: 9526\n"
     ]
    }
   ],
   "source": [
    "#Rerun this cell to simulate using random data points from the test set\n",
    "for i in range(0,10000):\n",
    "    randomData = random.choice(X_test)\n",
    "    validator = pickRandomValidator(clfList)\n",
    "    consensusPred = validateData(clfList, validator, randomData.reshape(1,-1))\n",
    "    if consensusPred > -1:\n",
    "        temp = Block(randomData, consensusPred)\n",
    "        test.addToChain(temp)\n",
    "    else:\n",
    "        failcount = failcount + 1\n",
    "    clfList.append(validator)\n",
    "\n",
    "print(\"Validation Failed \" + str(failcount) + \" times.\")\n",
    "print(\"Final block height: \" + str(len(test.getBlockList())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICK BEST PERFORMING VALIDATOR \n",
    "\n",
    "#### (Assumes that the models already have a prediction history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = Chain() #Instantiate a test blockchain\n",
    "validator2 = None\n",
    "\n",
    "failcount2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Failed 356 times.\n",
      "Final block height: 9644\n"
     ]
    }
   ],
   "source": [
    "#Rerun this cell to simulate using random data points from the test set\n",
    "for i in range(0,10000):\n",
    "    randomData = random.choice(X_test)\n",
    "    if validator2 is None:\n",
    "        validator2 = pickBestValidator(clfList)\n",
    "    consensusPred = validateData(clfList, validator2, randomData.reshape(1,-1))\n",
    "    if consensusPred > -1:\n",
    "        temp = Block(randomData, consensusPred)\n",
    "        test2.addToChain(temp)\n",
    "    else:\n",
    "        clfList.append(validator2)\n",
    "        validator2 = None\n",
    "        failcount2 = failcount2 + 1\n",
    "        \n",
    "print(\"Validation Failed \" + str(failcount2) + \" times.\")\n",
    "print(\"Final block height: \" + str(len(test2.getBlockList())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICK RANDOM VALIDATOR FROM TOP 5 PERFORMING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = Chain() #Instantiate a test blockchain\n",
    "validator3 = None\n",
    "\n",
    "failcount3 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Failed 359 times.\n",
      "Final block height: 9641\n"
     ]
    }
   ],
   "source": [
    "#Rerun this cell to simulate using random data points from the test set\n",
    "for i in range(0,10000):\n",
    "    randomData = random.choice(X_test)\n",
    "    if validator3 is None:\n",
    "        validator3 = pickFromTopValidator(clfList)\n",
    "    consensusPred = validateData(clfList, validator3, randomData.reshape(1,-1))\n",
    "    if consensusPred > -1:\n",
    "        temp = Block(randomData, consensusPred)\n",
    "        test3.addToChain(temp)\n",
    "    else:\n",
    "        clfList.append(validator2)\n",
    "        validator3 = None\n",
    "        failcount3 = failcount3 + 1\n",
    "        \n",
    "print(\"Validation Failed \" + str(failcount3) + \" times.\")\n",
    "print(\"Final block height: \" + str(len(test3.getBlockList())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
